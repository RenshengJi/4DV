# Stage 2 Online Training Configuration for VGGT
# 第二阶段在线训练配置 - 专注于渲染损失和动态对象精细化

# =============== 模型配置 ===============
model: "VGGT(img_size=518, patch_size=14, embed_dim=1024)"
pretrained: null  # 第二阶段需要加载第一阶段训练好的模型

# VGGT冻结策略配置
# 可选值: "none", "encoder", "encoder_frame", "backbone", "backbone_camera", "backbone_pts",
#        "vggt", "vggt_wo_velocity", "vggt_wo_depth", "vggt_wo_gaussian_and_velocity", "all"
# 第二阶段训练时冻结所有VGGT参数，只训练Stage2 refine模型
vggt_freeze_strategy: "all"


# =============== 辅助模型配置 ===============
auxiliary_models:
  # SAM2模型 (用于动态对象检测)
  # sam2: SAM2AutomaticMaskGenerator(SAM2Base(config_file="sam2.1_hiera_tiny.yaml",
  #   path="sam2.1_hiera_tiny.pt", offload=${offload_auxiliary}))

  # DAM2模型 (用于生成sky masks)
  # dam2: DepthAnythingV2(encoder="vitb", offload=${offload_auxiliary})

offload_auxiliary: False

# =============== 训练配置 ===============
load_only_encoder: False
long_context: True
fixed_length: False
resume: null  # 通常从第一阶段的checkpoint开始
benchmark: False
num_views: 32
num_test_views: 16
n_corres_train: 0
n_corres_test: 0

# =============== 训练阶段配置 ===============
# 第二阶段专用配置
training_stage: 'stage2'

# =============== 第一阶段损失权重配置 (第二阶段禁用) ===============
# 第二阶段训练时，第一阶段的所有损失都设为0

# 1. Self Render Loss (训练gaussian head) - 已弃用总权重，使用分项权重
self_render_weight: 0.0                    # 总权重 (已弃用)
self_render_rgb_weight: 0.0                # RGB损失权重
self_render_lpips_weight: 0.0              # LPIPS感知损失权重
self_render_depth_weight: 0.0              # 深度损失权重

# 2. Flow Loss (训练velocity head)
flow_loss_weight: 0.0                      # 光流监督velocity学习
flow_interval: 1                           # 光流计算的帧间隔 (保持配置)

# 3. SAM2 Velocity Consistency Loss (辅助velocity head监督)
sam2_velocity_weight: 0.0                  # SAM2掩码一致性监督
use_preprocessed_sam: false                 # SAM2推理模式配置 (保持配置)

# 4. Sky Opacity Loss (监督gaussian head的opacity参数)
sky_opacity_weight: 0.0                    # 天空区域opacity约束

# 5. Sky Color Loss (监督sky token以及sky head学习)
sky_color_weight: 0.0                      # 天空颜色预测监督

# 6. Velocity Regularization Loss (约束velocity值)
velocity_reg_weight: 0.0                   # 速度正则化约束

# 7. VGGT Distillation Loss (蒸馏损失，监督depth head、camera head等)
vggt_distill_weight: 0.0                   # VGGT teacher蒸馏监督

# 8. Camera Loss (监督camera head训练)
camera_loss_weight: 0.0                    # 相机参数预测损失权重

# 9. Depth Loss (监督depth head训练)
depth_loss_weight: 0.0                     # 深度预测损失权重

# =============== 第二阶段配置 ===============
# 启用第二阶段训练
enable_stage2: true
stage2_start_epoch: 0                     # 第二阶段从第0个epoch开始
stage2_frequency: 1                       # 每个iteration都进行第二阶段训练

# 第二阶段损失权重
stage2_loss_weight: 1.0                   # 第二阶段渲染损失权重

# 第二阶段模型配置
input_gaussian_dim: 14
output_gaussian_dim: 11
gaussian_feature_dim: 128
gaussian_num_layers: 2
gaussian_num_heads: 4
gaussian_mlp_ratio: 2.0
pose_feature_dim: 128
pose_num_heads: 4
pose_num_layers: 2
max_points_per_object: 2048
stage2_training_mode: 'refine'             # 第二阶段专用的refine模式

# 第二阶段损失配置
stage2_rgb_loss_weight: 1.0               # RGB渲染损失
stage2_depth_loss_weight: 0.1             # 深度渲染损失
stage2_lpips_loss_weight: 0.05            # LPIPS感知损失
stage2_consistency_loss_weight: 0.02      # 多视图一致性损失
stage2_gaussian_reg_weight: 0.005         # Gaussian参数正则化
stage2_pose_reg_weight: 0.005             # 位姿参数正则化
stage2_temporal_smooth_weight: 0.002      # 时序平滑损失

# 动态处理器配置
min_object_size: 100
max_objects_per_frame: 10
velocity_threshold_percentile: 0.75
enable_optical_flow_aggregation: true

# =============== 数据集配置 ===============

allow_repeat: False
train_dataset: Waymo_Multi(allow_repeat=${allow_repeat}, split=None,
  ROOT="/mnt/teams/algo-teams/yuxue.yang/4DVideo/preprocessed_dataset/waymo/train",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  aug_crop=0, resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], transform=ImgNorm,
  num_views=${num_views}, n_corres=${n_corres_train}, seq_aug_crop=True, load_sam_masks=False)

test_dataset: 1000 @ Waymo_Multi(split=None,
  ROOT="/mnt/teams/algo-teams/yuxue.yang/4DVideo/preprocessed_dataset/waymo/train",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], num_views=${num_test_views}, seed=42, n_corres=${n_corres_test})

# =============== 优化器配置 ===============
seed: 0
batch_size: 1
accum_iter: 4
gradient_checkpointing: True
epochs: 10                                 # 第二阶段通常需要较少epochs
start_epoch: 0
weight_decay: 0.01                         # 第二阶段使用较小的weight decay
lr: 1e-4                                   # 第二阶段使用较小的学习率
min_lr: 1e-8
warmup_epochs: 0.1                         # 第二阶段使用较短的warmup
amp: 1

# 第二阶段专用学习率配置
stage2_learning_rate: 5e-5                # 更小的学习率用于精细化
stage2_weight_decay: 0.005                # 更小的权重衰减

# =============== 训练监控配置 ===============
num_workers: 4
world_size: 1
local-rank: -1
dist_url: 'env://'
rank: 0
gpu: 0
distributed: False
dist_backend: 'nccl'

eval_freq: 1
save_freq: 0.2                             # 第二阶段更频繁保存
keep_freq: 1
print_freq: 5                              # 更频繁的打印
print_img_freq: 50000000
num_imgs_vis: 4

# =============== 输出配置 ===============
save_dir: 'checkpoints/waymo_stage2_online'
exp_name: 'stage2_online'
task: 'cut3r'
logdir: ./${save_dir}/${exp_name}/logs
output_dir: ./${save_dir}/${exp_name}/

# =============== Hydra配置 ===============
hydra:
  verbose: True
  run:
    dir: ./${save_dir}/${exp_name}