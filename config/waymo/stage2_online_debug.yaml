# Stage 2 Online Training Configuration for VGGT
# 第二阶段在线训练配置 - 专注于渲染损失和动态对象精细化

debug: True

# =============== 模型配置 ===============
model: "VGGT(img_size=518, patch_size=14, embed_dim=1024)"
# pretrained: model.pt  # 第二阶段需要加载第一阶段训练好的模型
# pretrained_velocity: "/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/checkpoints/waymo_stage1_online/aggregator_resume_noflowgrad_nearestdynamic/checkpoint-epoch_0_35805.pth" 
pretrained_velocity: "/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/checkpoints/waymo_stage1_online/aggregator_resume_noflowgrad_nearestdynamic_resume_0point1_novoxel/checkpoint-epoch_0_45568.pth"


# VGGT冻结策略配置
# 第二阶段训练时冻结所有VGGT参数，只训练Stage2 refine模型
# null表示不设置冻结策略（保持模型默认行为）
vggt_freeze_strategy: all


# =============== 辅助模型配置 ===============
auxiliary_models:
  # 光流模型 (用于flow_loss) - 第二阶段禁用
  flow: RAFT(RAFTCfg(name="kitti-M", dataset="kitti", path="Tartan-C-T-TSKH-kitti432x960-M.pth",
    use_var=True, var_min=0, var_max=10, pretrain="resnet34", initial_dim=64, block_dims=[64, 128, 256],
    radius=4, dim=128, num_blocks=2, iters=4, image_size=[432, 960],
    offload=${offload_auxiliary}, geo_thresh=2, photo_thresh=-1))

  # SAM2模型 (用于velocity consistency loss) - 第二阶段禁用
  # sam2: SAM2Base(config_file="sam2.1_hiera_t", path="sam2.1_hiera_tiny.pt",
  #   offload=${offload_auxiliary})

  # DAM2模型 (用于生成sky masks)
  dam2: DepthAnythingV2(encoder="vitb", offload=${offload_auxiliary})

  # # VGGT teacher模型 (用于渲染损失) - 第二阶段禁用
  # vggt_teacher: VGGT(path="/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/model.pt", offload=${offload_auxiliary})

offload_auxiliary: False

# =============== 训练配置 ===============
load_only_encoder: False
long_context: True
fixed_length: False
resume: null  # 通常从第一阶段的checkpoint开始
benchmark: False
num_views: 8
num_test_views: 16
n_corres_train: 0
n_corres_test: 0

# =============== 训练阶段配置 ===============
# 第二阶段专用配置
training_stage: 'stage2'

# =============== 第一阶段损失权重配置 (第二阶段禁用) ===============
# 第二阶段训练时，第一阶段的所有损失都设为0

lpips_start_iter: 0                     # LPIPS loss开始计算的iteration (保持配置)

# 1. Self Render Loss (训练gaussian head) - 已弃用总权重，使用分项权重
self_render_weight: 0.0                    # 总权重 (已弃用)
self_render_rgb_weight: 0.0                # RGB损失权重
self_render_lpips_weight: 0.0              # LPIPS感知损失权重
self_render_depth_weight: 0.0              # 深度损失权重

# 2. Flow Loss (训练velocity head)
flow_loss_weight: 0.0                      # 光流监督velocity学习
flow_interval: 1                           # 光流计算的帧间隔 (保持配置)

# 3. GT Flow Loss (直接使用GT flowmap监督velocity head)
# 类似depth loss，返回三个损失：conf、reg、grad
conf_flow_loss_weight: 0.0                 # GT flowmap conf损失权重
grad_flow_loss_weight: 0.0                 # GT flowmap gradient损失权重
reg_flow_loss_weight: 0.0                  # GT flowmap reg损失权重

# 4. SAM2 Velocity Consistency Loss (辅助velocity head监督)
sam2_velocity_weight: 0.0                  # SAM2掩码一致性监督
use_preprocessed_sam: false                 # SAM2推理模式配置 (保持配置)

# 5. Sky Opacity Loss (监督gaussian head的opacity参数)
sky_opacity_weight: 0.0                    # 天空区域opacity约束

# 6. Sky Color Loss (监督sky token以及sky head学习)
sky_color_weight: 0.0                      # 天空颜色预测监督

# 7. Velocity Regularization Loss (约束velocity值)
velocity_reg_weight: 0.0                   # 速度正则化约束

# 8. VGGT Distillation Loss (蒸馏损失，监督depth head、camera head等)
vggt_distill_weight: 0.0                   # VGGT teacher蒸馏监督

# 9. Camera Loss (监督camera head训练)
camera_loss_weight: 0.0                    # 相机参数预测损失权重

# 10. Depth Loss (监督depth head训练)
conf_depth_loss_weight: 0.0                # 深度预测损失权重
grad_depth_loss_weight: 0.0                # 深度梯度损失权重
reg_depth_loss_weight: 0.0                 # 深度正则化损失权重

# 11. Scale Loss (监督scale head训练，使用depth_scale_factor作为GT)
scale_loss_weight: 0.0                     # 场景尺度预测损失权重

# 12. Aggregator Render Loss (监督gaussian_head，辅助监督depth和velocity)
aggregator_render_rgb_weight: 0.0          # Aggregator render RGB损失权重
aggregator_render_depth_weight: 0.0        # Aggregator render depth损失权重
aggregator_render_lpips_weight: 0.0        # Aggregator render LPIPS损失权重
aggregator_voxel_size: 0.05                # 体素量化大小(metric尺度, 单位m) (保持配置)
aggregator_dynamic_threshold: 0.1          # 动静态分离的速度阈值(metric尺度, 单位m/s) (保持配置)

# =============== 第二阶段配置 ===============
# 启用第二阶段训练
enable_stage2: true
stage2_start_epoch: 0                     # 第二阶段从第0个epoch开始
stage2_frequency: 1                       # 每个iteration都进行第二阶段训练

# 第二阶段损失权重
stage2_loss_weight: 1.0                   # 第二阶段渲染损失权重

# 第二阶段模型配置（稀疏卷积）
# Gaussian细化网络配置
input_gaussian_dim: 14
output_gaussian_dim: 14
gaussian_feature_dim: 384                 # 特征维度，增加到384以提升网络容量
gaussian_num_conv_layers: 10              # 卷积层数，增加到10层以提升网络容量
gaussian_voxel_size: 0.05                 # Gaussian细化体素大小（米），保持高分辨率

# 位姿细化网络配置
pose_input_dim: 3                         # 输入维度（xyz坐标）
pose_feature_dim: 384                     # 特征维度，增加到384以提升网络容量
pose_num_conv_layers: 10                  # 卷积层数，增加到10层以提升网络容量
pose_voxel_size: 0.1                      # 位姿细化体素大小（米）
pose_max_points: 4096                     # 每个物体最大点数

# 训练模式
stage2_training_mode: 'joint'             # 第二阶段专用的refine模式：'joint', 'gaussian_only', 'pose_only'

# 第二阶段损失配置
stage2_rgb_loss_weight: 1.0               # RGB渲染损失
stage2_depth_loss_weight: 1.0             # 深度渲染损失
stage2_render_only_dynamic: true          # 是否只渲染动态物体（不渲染静态背景）
stage2_supervise_only_dynamic: true       # 是否只监督动态区域（使用2D pixel mask）
stage2_static_black_weight: 1.0           # 非动态区域渲染为黑色的loss权重

# 动态处理器配置
min_object_size: 100                      # 最小物体尺寸（点数）
max_objects_per_frame: 10                 # 每帧最大物体数量
enable_optical_flow_aggregation: true     # 是否使用光流聚合
use_velocity_based_transform: true       # 是否使用velocity直接计算变换（false=光流方法，true=velocity方法）

# Stage 2: 动态物体聚类参数
velocity_threshold: 0.1                   # 速度阈值（metric尺度，m/s）
clustering_eps: 0.02                      # DBSCAN邻域半径
clustering_min_samples: 10                # DBSCAN最小样本数

# Stage 3: 跨帧跟踪参数
tracking_position_threshold: 2.0          # 位置匹配阈值
tracking_velocity_threshold: 0.2          # 速度匹配阈值

# =============== 数据集配置 ===============

allow_repeat: False

train_dataset: Waymo_Multi(allow_repeat=${allow_repeat}, split=None,
  ROOT="/mnt/teams/algo-teams/yuxue.yang/4DVideo/preprocessed_dataset/waymo/train_with_flow",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  aug_crop=0, resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], transform=ImgNorm,
  num_views=${num_views}, n_corres=${n_corres_train}, seq_aug_crop=True, load_sam_masks=False)

test_dataset: 1000 @ Waymo_Multi(split=None,
  ROOT="/mnt/teams/algo-teams/yuxue.yang/4DVideo/preprocessed_dataset/waymo/test_with_flow",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], num_views=${num_test_views}, seed=42, n_corres=${n_corres_test})

# =============== 优化器配置 ===============
seed: 0
batch_size: 1
accum_iter: 4
gradient_checkpointing: True
epochs: 10                                 # 第二阶段通常需要较少epochs
start_epoch: 0
weight_decay: 0.005                        # 权重衰减（用于所有参数包括Stage2）
lr: 5e-4                                   # 学习率（用于所有参数包括Stage2）
min_lr: 1e-6
warmup_epochs: 0.1                         # 第二阶段使用较短的warmup
amp: 1

# =============== 训练监控配置 ===============
num_workers: 4
world_size: 1
local-rank: -1
dist_url: 'env://'
rank: 0
gpu: 0
distributed: False
dist_backend: 'nccl'

eval_freq: 1
save_freq: 0.01                             # 第二阶段更频繁保存
keep_freq: 1
print_freq: 5                              # 更频繁的打印
print_img_freq: 50000000
num_imgs_vis: 4

# =============== 输出配置 ===============
save_dir: 'checkpoints/waymo_stage2_online_debug'
exp_name: 'stage2_train+5e-4+biggermodel'
task: 'cut3r'
logdir: ./${save_dir}/${exp_name}/logs
output_dir: ./${save_dir}/${exp_name}/

# =============== Hydra配置 ===============
hydra:
  verbose: True
  run:
    dir: ./${save_dir}/${exp_name}