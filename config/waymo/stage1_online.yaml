# Stage 1 Online Training Configuration for VGGT
# 第一阶段在线训练配置 - 包含统一的损失权重管理

# debug: true

# =============== 模型配置 ===============
model: "VGGT(img_size=518, patch_size=14, embed_dim=1024, sh_degree=0, use_gs_head=True, use_gs_head_velocity=False)"
# sh_degree: 球谐函数的阶数（0=只有DC分量3个参数，1=DC+方向性12个参数，2=27个参数，3=48个参数）
# use_gs_head: 是否对gaussian_head使用DPTGSHead (True=DPTGSHead, False=DPTHead)
#   - True: gaussian_head使用DPTGSHead (默认)
#   - False: gaussian_head使用普通DPTHead
# use_gs_head_velocity: 是否对velocity_head使用DPTGSHead (True=DPTGSHead, False=DPTHead)
#   - True: velocity_head使用DPTGSHead
#   - False: velocity_head使用普通DPTHead (默认)
# Gaussian head的output_dim会根据sh_degree自动计算：11 + 3*(sh_degree+1)^2

# 相机参数配置
use_gt_camera: True  # 是否在模型forward中使用GT相机参数来计算world_points
                      # True: 使用GT的extrinsics和intrinsics (默认)
                      # False: 使用模型预测的pose_enc

pretrained: model.pt
pretrained_velocity: False
# pretrained_velocity: "checkpoints/waymo_new/segmetation+degree0+lr5e-5forreusme_resumefrombefore/checkpoint-epoch_0_13020.pth"

# VGGT冻结策略配置
# 可选值: "none", "encoder", "encoder_frame", "backbone", "backbone_camera", "backbone_pts",
#        "vggt", "vggt_wo_velocity", "vggt_wo_depth", "vggt_wo_gaussian_and_velocity", "all", "old"
# null表示不设置冻结策略（保持模型默认行为）
vggt_freeze_strategy: null


# =============== 辅助模型配置 ===============
auxiliary_models:
  # # 光流模型 (用于flow_loss)
  # flow: RAFT(RAFTCfg(name="kitti-M", dataset="kitti", path="Tartan-C-T-TSKH-kitti432x960-M.pth",
  #   use_var=True, var_min=0, var_max=10, pretrain="resnet34", initial_dim=64, block_dims=[64, 128, 256],
  #   radius=4, dim=128, num_blocks=2, iters=4, image_size=[432, 960],
  #   offload=${offload_auxiliary}, geo_thresh=2, photo_thresh=-1))

  # SAM2模型 (用于velocity consistency loss)
  # sam2: SAM2Base(config_file="sam2.1_hiera_t", path="sam2.1_hiera_tiny.pt",
  #   offload=${offload_auxiliary})

  # DAM2模型 (用于生成sky masks)
  dam2: DepthAnythingV2(encoder="vitb", offload=${offload_auxiliary})

  # # VGGT teacher模型 (用于渲染损失)
  # vggt_teacher: VGGT(path="src/model.pt", offload=${offload_auxiliary})

offload_auxiliary: False

# =============== 训练配置 ===============
load_only_encoder: False
long_context: True
fixed_length: False
resume: null
benchmark: False
num_views: 8
num_test_views: 16
n_corres_train: 0
n_corres_test: 0

# =============== 第一阶段损失权重配置 ===============
# 权重为0则完全不计算该损失

# 1. Self Render Loss (训练gaussian head)
self_render_weight: 0.0                    # Gaussian参数学习的主要损失
self_render_rgb_weight: 1.0                # RGB损失权重
self_render_lpips_weight: 0.0              # LPIPS感知损失权重
self_render_depth_weight: 0.0              # 深度损失权重

# 2. Flow Loss (训练velocity head)
flow_loss_weight: 0.0                      # 光流监督velocity学习
flow_interval: 1                           # 光流计算的帧间隔

# 3. GT Flow Loss (直接使用GT flowmap监督velocity head)
# 类似depth loss，返回三个损失：conf、reg、grad
conf_flow_loss_weight: 0.0                 # GT flowmap conf损失权重
grad_flow_loss_weight: 0.0                 # GT flowmap gradient损失权重
reg_flow_loss_weight: 0.0                  # GT flowmap reg损失权重

# 3b. GT Flow Loss Ours (我们自己实现的版本)
gt_flow_loss_ours_weight: 1.0              # 自定义GT flowmap损失权重

# 4. SAM2 Velocity Consistency Loss (辅助velocity head监督)
sam2_velocity_weight: 0.0                  # SAM2掩码一致性监督
use_preprocessed_sam: false                 # false=在线推理SAM2, true=使用预处理掩码

# 5. Sky Opacity Loss (监督gaussian head的opacity参数)
sky_opacity_weight: 1.0                    # 天空区域opacity约束

# 6. Sky Color Loss (监督sky token以及sky head学习)
sky_color_weight: 0.0                      # 天空颜色预测监督 (已融合到self_render_loss中)

# 7. Velocity Regularization Loss (约束velocity值)
velocity_reg_weight: 0.0                 # 速度正则化约束

# 8. VGGT Distillation Loss (蒸馏损失，监督depth head、camera head等)
vggt_distill_weight: 0.0                  # VGGT teacher蒸馏监督，防止unfreeze backbone时输出漂移

# 9. Camera Loss (监督camera head训练)
camera_loss_weight: 5.0                   # 相机参数预测损失权重

# 10. Depth Loss (监督depth head训练)
conf_depth_loss_weight: 1.0                    # 深度预测损失权重
grad_depth_loss_weight: 0.0                 # 深度梯度损失权重
reg_depth_loss_weight: 1.0                      # 深度正则化损失权重

# 11. Scale Loss (监督scale head训练，使用depth_scale_factor作为GT)
scale_loss_weight: 1.0                      # 场景尺度预测损失权重

# 12. Aggregator Render Loss (监督gaussian_head，辅助监督depth和velocity)
aggregator_render_rgb_weight: 0.0           # Aggregator render RGB损失权重
aggregator_render_depth_weight: 0.0         # Aggregator render depth损失权重
aggregator_render_lpips_weight: 0.0         # Aggregator render LPIPS损失权重
aggregator_voxel_size: 0                # 体素量化大小(metric尺度, 单位m)
aggregator_dynamic_threshold: 0.1          # 动静态分离的速度阈值(metric尺度, 单位m/s)
aggregator_frame_sample_ratio: 1.0         # Aggregator渲染时的帧采样比例(用于控制渲染的帧数量)

# 13. Aggregator_all Render Loss (代替Stage2 refine网络的渲染loss)
# 这个loss直接在Stage1中使用动态物体处理+渲染监督,跳过Stage2的refine网络
aggregator_all_start_iter: 10000           # Aggregator_all loss开始计算的iteration (默认50k)
aggregator_all_render_rgb_weight: 1.0      # Aggregator_all RGB渲染损失权重
aggregator_all_render_depth_weight: 1.0    # Aggregator_all depth渲染损失权重
aggregator_all_render_lpips_weight: 0.1    # Aggregator_all LPIPS渲染损失权重
# Stage2配置（用于aggregator_all loss的渲染配置）
stage2_render_only_dynamic: false          # 是否只渲染动态物体
stage2_supervise_only_dynamic: false       # 是否只监督动态区域
# 动态处理器配置（用于aggregator_all loss的动态物体处理）
min_object_size: 500                       # 最小物体尺寸（点数）
max_objects_per_frame: 10                  # 每帧最大物体数量
velocity_threshold: 0.1                    # 速度阈值（metric尺度，m/s）
clustering_eps: 0.3                       # DBSCAN邻域半径
clustering_min_samples: 10                 # DBSCAN最小样本数
tracking_position_threshold: 2.0           # 位置匹配阈值
tracking_velocity_threshold: 0.2           # 速度匹配阈值
enable_optical_flow_aggregation: true      # 是否使用光流聚合
use_velocity_based_transform: true        # 是否使用velocity直接计算变换（false=光流方法，true=velocity方法）
velocity_transform_mode: "procrustes"          # velocity变换模式: "simple"(仅T)或"procrustes"(R+T)

# =============== 数据集配置 ===============

allow_repeat: False

train_dataset: 2 * Waymo_Multi(allow_repeat=${allow_repeat}, split=None,
  ROOT="../data/waymo/train_full",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  aug_crop=0, resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], transform=ImgNorm,
  num_views=${num_views}, n_corres=${n_corres_train}, seq_aug_crop=True, load_sam_masks=False)

test_dataset: 1000 @ Waymo_Multi(split=None,
  ROOT="../data/waymo/train_full",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], num_views=${num_test_views}, seed=42, n_corres=${n_corres_test})

# =============== 优化器配置 ===============
seed: 0
batch_size: 1
accum_iter: 4
gradient_checkpointing: True
epochs: 1
start_epoch: 0
weight_decay: 0.05
lr: 1e-4
min_lr: 1e-8
warmup_epochs: 0.02
amp: 1

# =============== 训练监控配置 ===============
num_workers: 4
world_size: 1
local-rank: -1
dist_url: 'env://'
rank: 0
gpu: 0
distributed: False
dist_backend: 'nccl'

eval_freq: 1
save_freq: 0.05                             # 每10%的epoch保存一次
keep_freq: 2
print_freq: 10
print_img_freq: 50000000
num_imgs_vis: 4

# =============== 输出配置 ===============
save_dir: 'checkpoints/new'
# exp_name: 'aggregator_from_scratch'
exp_name: 'start'
task: 'cut3r'
logdir: ./${save_dir}/${exp_name}/logs
output_dir: ./${save_dir}/${exp_name}/

# =============== Hydra配置 ===============
hydra:
  verbose: False
  run:
    dir: ./${save_dir}/${exp_name}