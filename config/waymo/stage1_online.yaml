# Stage 1 Online Training Configuration for VGGT
# 第一阶段在线训练配置 - 包含统一的损失权重管理

# =============== 模型配置 ===============
model: "VGGT(img_size=518, patch_size=14, embed_dim=1024)"
# pretrained: model.pt
# pretrained_velocity: False
pretrained_velocity: "/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/checkpoints/waymo_stage1_online/aggregator_all/checkpoint-epoch_0_28480.pth"
# pretrained_velocity: "/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/checkpoints/waymo_stage1_online/aggregator_resume_noflowgrad_nearestdynamic_resume_0point1_novoxel/checkpoint-epoch_0_19936.pth"
# pretrained_velocity: "/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/checkpoints/waymo_stage1_online/stage1_gtflow/checkpoint-epoch_7_9968.pth"

# VGGT冻结策略配置
# 可选值: "none", "encoder", "encoder_frame", "backbone", "backbone_camera", "backbone_pts",
#        "vggt", "vggt_wo_velocity", "vggt_wo_depth", "vggt_wo_gaussian_and_velocity", "all", "old"
# null表示不设置冻结策略（保持模型默认行为）
vggt_freeze_strategy: null


# =============== 辅助模型配置 ===============
auxiliary_models:
  # # 光流模型 (用于flow_loss)
  # flow: RAFT(RAFTCfg(name="kitti-M", dataset="kitti", path="Tartan-C-T-TSKH-kitti432x960-M.pth",
  #   use_var=True, var_min=0, var_max=10, pretrain="resnet34", initial_dim=64, block_dims=[64, 128, 256],
  #   radius=4, dim=128, num_blocks=2, iters=4, image_size=[432, 960],
  #   offload=${offload_auxiliary}, geo_thresh=2, photo_thresh=-1))

  # SAM2模型 (用于velocity consistency loss)
  # sam2: SAM2Base(config_file="sam2.1_hiera_t", path="sam2.1_hiera_tiny.pt",
  #   offload=${offload_auxiliary})

  # DAM2模型 (用于生成sky masks)
  dam2: DepthAnythingV2(encoder="vitb", offload=${offload_auxiliary})

  # # VGGT teacher模型 (用于渲染损失)
  # vggt_teacher: VGGT(path="/mnt/teams/algo-teams/yuxue.yang/4DVideo/ziqi/4DVideo/src/model.pt", offload=${offload_auxiliary})

offload_auxiliary: False

# =============== 训练配置 ===============
load_only_encoder: False
long_context: True
fixed_length: False
resume: null
benchmark: False
num_views: 8
num_test_views: 16
n_corres_train: 0
n_corres_test: 0

# =============== 训练阶段配置 ===============
# 'stage1': 第一阶段训练 - 训练VGGT主模型的gaussian head, velocity head等
# 'stage2': 第二阶段训练 - 只训练refine模型，包含渲染损失
# 'joint': 联合训练模式 - 同时训练两个阶段（实验性）
training_stage: 'stage1'

# =============== 第一阶段损失权重配置 ===============
# 权重为0则完全不计算该损失

lpips_start_iter: 5000                     # LPIPS loss开始计算的iteration

# 1. Self Render Loss (训练gaussian head)
self_render_weight: 0.0                    # Gaussian参数学习的主要损失 (已弃用，使用下面的分项权重)
self_render_rgb_weight: 1.0                # RGB损失权重
self_render_lpips_weight: 0.1              # LPIPS感知损失权重
self_render_depth_weight: 1.0              # 深度损失权重

# 2. Flow Loss (训练velocity head)
flow_loss_weight: 0.0                      # 光流监督velocity学习
flow_interval: 1                           # 光流计算的帧间隔

# 3. GT Flow Loss (直接使用GT flowmap监督velocity head)
# 类似depth loss，返回三个损失：conf、reg、grad
conf_flow_loss_weight: 0.0                 # GT flowmap conf损失权重
grad_flow_loss_weight: 0.0                 # GT flowmap gradient损失权重
reg_flow_loss_weight: 0.0                  # GT flowmap reg损失权重

# 3b. GT Flow Loss Ours (我们自己实现的版本)
gt_flow_loss_ours_weight: 1.0              # 自定义GT flowmap损失权重

# 4. SAM2 Velocity Consistency Loss (辅助velocity head监督)
sam2_velocity_weight: 0.0                  # SAM2掩码一致性监督
use_preprocessed_sam: false                 # false=在线推理SAM2, true=使用预处理掩码

# 5. Sky Opacity Loss (监督gaussian head的opacity参数)
sky_opacity_weight: 1.0                    # 天空区域opacity约束

# 6. Sky Color Loss (监督sky token以及sky head学习)
sky_color_weight: 0.0                      # 天空颜色预测监督 (已融合到self_render_loss中)

# 7. Velocity Regularization Loss (约束velocity值)
velocity_reg_weight: 0.05                 # 速度正则化约束

# 8. VGGT Distillation Loss (蒸馏损失，监督depth head、camera head等)
vggt_distill_weight: 0.0                  # VGGT teacher蒸馏监督，防止unfreeze backbone时输出漂移

# 9. Camera Loss (监督camera head训练)
camera_loss_weight: 5.0                   # 相机参数预测损失权重

# 10. Depth Loss (监督depth head训练)
conf_depth_loss_weight: 1.0                    # 深度预测损失权重
grad_depth_loss_weight: 1.0                 # 深度梯度损失权重
reg_depth_loss_weight: 1.0                      # 深度正则化损失权重

# 11. Scale Loss (监督scale head训练，使用depth_scale_factor作为GT)
scale_loss_weight: 1.0                      # 场景尺度预测损失权重

# 12. Aggregator Render Loss (监督gaussian_head，辅助监督depth和velocity)
aggregator_render_rgb_weight: 0.0           # Aggregator render RGB损失权重
aggregator_render_depth_weight: 0.0         # Aggregator render depth损失权重
aggregator_render_lpips_weight: 0.0         # Aggregator render LPIPS损失权重
aggregator_voxel_size: 0                # 体素量化大小(metric尺度, 单位m)
aggregator_dynamic_threshold: 0.1          # 动静态分离的速度阈值(metric尺度, 单位m/s)
aggregator_frame_sample_ratio: 0.25         # Aggregator渲染时的帧采样比例(用于控制渲染的帧数量)

# 13. Aggregator_all Render Loss (代替Stage2 refine网络的渲染loss)
# 这个loss直接在Stage1中使用动态物体处理+渲染监督,跳过Stage2的refine网络
# 需要enable_stage2=true才能使用(需要OnlineDynamicProcessor和Stage2Loss)
aggregator_all_render_rgb_weight: 1.0      # Aggregator_all RGB渲染损失权重
aggregator_all_render_depth_weight: 1.0    # Aggregator_all depth渲染损失权重
aggregator_all_static_black_weight: 0.0    # 非动态区域渲染为黑色的loss权重
# Stage2配置（用于aggregator_all loss的渲染配置）
stage2_render_only_dynamic: false          # 是否只渲染动态物体
stage2_supervise_only_dynamic: false       # 是否只监督动态区域
stage2_static_black_weight: 0.0            # 非动态区域渲染为黑色的loss权重
# 动态处理器配置（用于aggregator_all loss的动态物体处理）
min_object_size: 3000                       # 最小物体尺寸（点数）
max_objects_per_frame: 10                  # 每帧最大物体数量
velocity_threshold: 0.1                    # 速度阈值（metric尺度，m/s）
clustering_eps: 0.02                       # DBSCAN邻域半径
clustering_min_samples: 10                 # DBSCAN最小样本数
tracking_position_threshold: 2.0           # 位置匹配阈值
tracking_velocity_threshold: 0.2           # 速度匹配阈值
enable_optical_flow_aggregation: true      # 是否使用光流聚合
use_velocity_based_transform: true        # 是否使用velocity直接计算变换（false=光流方法，true=velocity方法）
velocity_transform_mode: "procrustes"          # velocity变换模式: "simple"(仅T)或"procrustes"(R+T)

# =============== 数据集配置 ===============

allow_repeat: False

train_dataset: Waymo_Multi(allow_repeat=${allow_repeat}, split=None,
  ROOT="/mnt/teams/algo-teams/yuxue.yang/4DVideo/preprocessed_dataset/waymo/train_with_flow",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  aug_crop=0, resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], transform=ImgNorm,
  num_views=${num_views}, n_corres=${n_corres_train}, seq_aug_crop=True, load_sam_masks=False)

test_dataset: 1000 @ Waymo_Multi(split=None,
  ROOT="/mnt/teams/algo-teams/yuxue.yang/4DVideo/preprocessed_dataset/waymo/train_with_flow",
  img_ray_mask_p=[1.0, 0.0, 0.0], valid_camera_id_list=["1", "2", "3"],
  resolution=[(518, 378),(518, 336),(518, 294),(518, 252),(518, 210),(518, 140),(378, 518),(336, 518),(294, 518),(252, 518)], num_views=${num_test_views}, seed=42, n_corres=${n_corres_test})

# =============== 优化器配置 ===============
seed: 0
batch_size: 1
accum_iter: 4
gradient_checkpointing: True
epochs: 2
start_epoch: 0
weight_decay: 0.05
lr: 3e-6
min_lr: 1e-8
warmup_epochs: 0.02
amp: 1

# =============== 训练监控配置 ===============
num_workers: 4
world_size: 1
local-rank: -1
dist_url: 'env://'
rank: 0
gpu: 0
distributed: False
dist_backend: 'nccl'

eval_freq: 1
save_freq: 0.05                             # 每10%的epoch保存一次
keep_freq: 2
print_freq: 10
print_img_freq: 50000000
num_imgs_vis: 4

# =============== 输出配置 ===============
save_dir: 'checkpoints/waymo_stage1_online'
# exp_name: 'aggregator_from_scratch'
exp_name: 'fromaggregator_all_lr3e-6_procrustes_area3000_velocityconstraint0.05'
task: 'cut3r'
logdir: ./${save_dir}/${exp_name}/logs
output_dir: ./${save_dir}/${exp_name}/

# =============== 第二阶段配置 ===============
# 注意：如果使用 aggregator_all_render loss，需要设置 enable_stage2: true
# 但保持 training_stage: 'stage1'，这样只初始化动态处理器和loss，不训练refine网络
enable_stage2: false                       # 设为true以启用aggregator_all loss
stage2_start_epoch: 999                    # 设置很大的值以禁用Stage2训练
stage2_frequency: 999

# =============== Hydra配置 ===============
hydra:
  verbose: True
  run:
    dir: ./${save_dir}/${exp_name}